{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all needed libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "# distilbert-base-uncased-finetuned-sst-2-english\n",
    "# Trained on BERT base model as a teacher\n",
    "from transformers import pipeline\n",
    "classifier1 = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def bert_distilbert(text):\n",
    "    text = str(text)\n",
    "    if text == 'nan ' or text == '':\n",
    "        return math.nan\n",
    "    return classifier1(text)\n",
    "# This a bert-base-multilingual-uncased model finetuned for sentiment analysis on product reviews\n",
    "# in six languages: English, Dutch, German, French, Spanish and Italian\n",
    "# It predicts the sentiment of the review as a number of stars (between 1 and 5)\n",
    "classifier2 = pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')  \n",
    "\n",
    "def bert_multilingual(text):\n",
    "    text = str(text)\n",
    "    if text == 'nan ' or text == '':\n",
    "        return math.nan\n",
    "    return classifier2(text)\n",
    "# The model was fine-tuned and evaluated on 15 data sets from diverse text sources to enhance \n",
    "# generalization across different types of texts (reviews, tweets, etc.)\n",
    "classifier3 = pipeline('sentiment-analysis', model='siebert/sentiment-roberta-large-english')   \n",
    "\n",
    "def roberta_english(text):\n",
    "    text = str(text)\n",
    "    if text == 'nan ' or text == '':\n",
    "        return math.nan\n",
    "    return classifier3(text)\n",
    "# This is a roBERTa-base model trained on ~58M tweets and finetuned for sentiment analysis \n",
    "# with the TweetEval benchmark.\n",
    "# Labels: 0 -> Negative; 1 -> Neutral; 2 -> Positive\n",
    "classifier4 = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment')     \n",
    "\n",
    "def roberta_tweet(text):\n",
    "    text = str(text)\n",
    "    if text == 'nan ' or text == '':\n",
    "        return math.nan\n",
    "    return classifier4(text)\n",
    "\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "sid_obj= SentimentIntensityAnalyzer()\n",
    "from sentifish import Sentiment\n",
    "from afinn import Afinn\n",
    "afn = Afinn()\n",
    "\n",
    "def textblob(text):\n",
    "    text = str(text)\n",
    "    res = TextBlob(text)\n",
    "    return res.sentiment.polarity\n",
    "\n",
    "def vader(text):\n",
    "    text = str(text)\n",
    "    temp = sid_obj.polarity_scores(sentence)\n",
    "    return temp['compound']\n",
    "\n",
    "def sentifish(text):\n",
    "    text = str(text)\n",
    "    obj=Sentiment(text)\n",
    "    polarity = obj.analyze( )\n",
    "    return polarity\n",
    "\n",
    "def afinn(text):\n",
    "    text = str(text)\n",
    "    return afn.score(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy import displacy\n",
    "    \n",
    "def dataframe_display(text):\n",
    "    doc = nlp(text)\n",
    "    print(doc)\n",
    "    df = pd.DataFrame(columns=['token','.dep_','.pos_','.tag_','children','children.pos_','children.text'])\n",
    "    for token in doc:\n",
    "        c = []\n",
    "        p = []\n",
    "        t = []\n",
    "        for children in token.children:\n",
    "            c.append(children)\n",
    "            p.append(children.pos_)\n",
    "            t.append(children.text)\n",
    "        df2 = {'token':token,\n",
    "              '.dep_':token.dep_,\n",
    "              '.pos_':token.pos_,\n",
    "              '.tag_':token.tag_,\n",
    "              'children':c,\n",
    "              'children.pos_':p,\n",
    "              'children.text':t}\n",
    "        df = df.append(df2, ignore_index = True)\n",
    "    display(pd_centered(df))\n",
    "    \n",
    "def pos_display(text):\n",
    "    print(text)\n",
    "    doc = nlp(text)\n",
    "    sentence_spans = list(doc.sents)\n",
    "    options = {'distance': 100}\n",
    "    displacy.render(sentence_spans, style='dep',jupyter=True,options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list(lis):\n",
    "    print(\"Length of list:\",len(lis))\n",
    "    for i in range(len(lis)):\n",
    "        print(lis[i])\n",
    "        \n",
    "def pd_centered(df):\n",
    "    return df.style.set_table_styles([\n",
    "        {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]},\n",
    "        {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1079, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Sample_for testing - Sheet1.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Room, hotel, menu everything was just perf...</td>\n",
       "      <td>2591082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>2591117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's spacious, neat &amp; clean. Ordered misal pav...</td>\n",
       "      <td>2590678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decent size rooms and the heating was very eff...</td>\n",
       "      <td>2590050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>2589882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review_content       id\n",
       "0  The Room, hotel, menu everything was just perf...  2591082\n",
       "1  Excellent experience to spend time in this res...  2591117\n",
       "2  It's spacious, neat & clean. Ordered misal pav...  2590678\n",
       "3  Decent size rooms and the heating was very eff...  2590050\n",
       "4  If zero Rating is available, this deserves the...  2589882"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cd = pd.DataFrame(columns = ['row','Reviewcontent','ReviewContentPos','ReviewContentNeg','ReviewContentNeu'])\n",
    "\n",
    "counter = 0\n",
    "for i in range(df.shape[0]):\n",
    "#     print(i)\n",
    "    if df.loc[i,'review_content']=='There are no comments available for this review':\n",
    "        df.loc[i,'review_content'] = math.nan\n",
    "#         print(i)\n",
    "    try:\n",
    "        if math.isnan(df.loc[i,'review_content']):\n",
    "            counter += 1\n",
    "            continue\n",
    "    except:\n",
    "        a = 1\n",
    "    \n",
    "    text = df.loc[i,'review_content']\n",
    "    now = text\n",
    "    now = now.split('\\n')\n",
    "    pos = math.nan\n",
    "    neg = math.nan\n",
    "    neu = math.nan\n",
    "            \n",
    "    for j in range(len(now)):\n",
    "        x = now[j].split()\n",
    "        if len(x)==0:\n",
    "            continue\n",
    "        if x[0] == '[Positive]:':\n",
    "            pos = ' '.join(x[1:])\n",
    "        elif x[0] == '[Negative]:':\n",
    "            neg = ' '.join(x[1:])\n",
    "        else:\n",
    "            neu = ' '.join(x)\n",
    "    df2 = {'row':i,\n",
    "           'Reviewcontent':df.loc[i,'review_content'],\n",
    "           'ReviewContentPos':pos,\n",
    "           'ReviewContentNeg':neg,\n",
    "           'ReviewContentNeu':neu}\n",
    "    cd = cd.append(df2, ignore_index = True)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd[\"ReviewContentPos\"] = cd[\"ReviewContentPos\"].astype(str)\n",
    "cd[\"ReviewContentNeg\"] = cd[\"ReviewContentNeg\"].astype(str)\n",
    "cd[\"ReviewContentNeu\"] = cd[\"ReviewContentNeu\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>Reviewcontent</th>\n",
       "      <th>ReviewContentPos</th>\n",
       "      <th>ReviewContentNeg</th>\n",
       "      <th>ReviewContentNeu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Room, hotel, menu everything was just perf...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>The Room, hotel, menu everything was just perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It's spacious, neat &amp; clean. Ordered misal pav...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>It's spacious, neat &amp; clean. Ordered misal pav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent size rooms and the heating was very eff...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Decent size rooms and the heating was very eff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent resort with on the toe services by e...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Excellent resort with on the toe services by e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[Positive]: Staff courtesy\\n[Negative]: Food w...</td>\n",
       "      <td>Staff courtesy</td>\n",
       "      <td>Food was terrible. Restaurant service pathetic</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>One of the most memorable bday ever Thanku so ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>One of the most memorable bday ever Thanku so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Nice for parties. Food very greasy. Not recomm...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Nice for parties. Food very greasy. Not recomm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>The place is cozy, my reservation was upgraded...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>The place is cozy, my reservation was upgraded...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row                                      Reviewcontent ReviewContentPos  \\\n",
       "0   0  The Room, hotel, menu everything was just perf...              nan   \n",
       "1   1  Excellent experience to spend time in this res...              nan   \n",
       "2   2  It's spacious, neat & clean. Ordered misal pav...              nan   \n",
       "3   3  Decent size rooms and the heating was very eff...              nan   \n",
       "4   4  If zero Rating is available, this deserves the...              nan   \n",
       "5   5  Excellent resort with on the toe services by e...              nan   \n",
       "6   6  [Positive]: Staff courtesy\\n[Negative]: Food w...   Staff courtesy   \n",
       "7   7  One of the most memorable bday ever Thanku so ...              nan   \n",
       "8   8  Nice for parties. Food very greasy. Not recomm...              nan   \n",
       "9   9  The place is cozy, my reservation was upgraded...              nan   \n",
       "\n",
       "                                 ReviewContentNeg  \\\n",
       "0                                             nan   \n",
       "1                                             nan   \n",
       "2                                             nan   \n",
       "3                                             nan   \n",
       "4                                             nan   \n",
       "5                                             nan   \n",
       "6  Food was terrible. Restaurant service pathetic   \n",
       "7                                             nan   \n",
       "8                                             nan   \n",
       "9                                             nan   \n",
       "\n",
       "                                    ReviewContentNeu  \n",
       "0  The Room, hotel, menu everything was just perf...  \n",
       "1  Excellent experience to spend time in this res...  \n",
       "2  It's spacious, neat & clean. Ordered misal pav...  \n",
       "3  Decent size rooms and the heating was very eff...  \n",
       "4  If zero Rating is available, this deserves the...  \n",
       "5  Excellent resort with on the toe services by e...  \n",
       "6                                                nan  \n",
       "7  One of the most memorable bday ever Thanku so ...  \n",
       "8  Nice for parties. Food very greasy. Not recomm...  \n",
       "9  The place is cozy, my reservation was upgraded...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Remove Punctuations without fullstop\n",
    "rem_pun = '!\"#$%&\\'()*+-/:;<=>?@[\\\\]^_`{|}~'\n",
    "def remove_punctuation_without_full(text):\n",
    "    punctuationfree=\"\".join([i if i not in rem_pun else ' ' for i in text])\n",
    "    return punctuationfree\n",
    "\n",
    "# Remove Numbers\n",
    "def remove_numbers(text):\n",
    "    pattern = r'[0-9]'\n",
    "    line = re.sub(pattern,' ', text)\n",
    "    return line\n",
    "\n",
    "# Remove non ascii characters\n",
    "def remove_non_ascii(text):\n",
    "    now = text\n",
    "    now = now.strip().split()\n",
    "    now = [''.join([i for i in word if ord(i) < 128]) for word in now]\n",
    "    text = \"\"\n",
    "    for i in range(len(now)):\n",
    "        text = text + now[i] + \" \"\n",
    "    return text\n",
    "\n",
    "# Convert multiple spaces to single space\n",
    "def convert_multiple_spaces(text):\n",
    "    answer = re.sub(' +', ' ', text)\n",
    "    return answer\n",
    "\n",
    "# Remove first and  end spaces\n",
    "def remove_first_end_spaces(string):\n",
    "    return \"\".join(string.rstrip().lstrip())\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemma(text):\n",
    "    now = text\n",
    "    now = now.strip().split()\n",
    "    now = [lemmatizer.lemmatize(word) for word in now]\n",
    "    text = \"\"\n",
    "    for i in range(len(now)):\n",
    "        text = text + now[i] + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Started...\n",
      "Preprocessing Done!\n"
     ]
    }
   ],
   "source": [
    "print('Preprocessing Started...')\n",
    "\n",
    "cd['clean_Reviewcontent'] = cd['Reviewcontent'].apply(lambda x:remove_punctuation_without_full(x))\n",
    "cd['clean_Reviewcontent'] = cd['clean_Reviewcontent'].apply(lambda x:remove_numbers(x))\n",
    "cd['clean_Reviewcontent'] = cd['clean_Reviewcontent'].apply(lambda x:remove_non_ascii(x))\n",
    "cd['clean_Reviewcontent'] = cd['clean_Reviewcontent'].apply(lambda x:lemma(x))\n",
    "cd['clean_Reviewcontent'] = cd['clean_Reviewcontent'].apply(lambda x:convert_multiple_spaces(x))\n",
    "cd['clean_Reviewcontent'] = cd['clean_Reviewcontent'].apply(lambda x:remove_first_end_spaces(x))\n",
    "\n",
    "cd['clean_ReviewContentPos'] = cd['ReviewContentPos'].apply(lambda x:remove_punctuation_without_full(x))\n",
    "cd['clean_ReviewContentPos'] = cd['clean_ReviewContentPos'].apply(lambda x:remove_numbers(x))\n",
    "cd['clean_ReviewContentPos'] = cd['clean_ReviewContentPos'].apply(lambda x:remove_non_ascii(x))\n",
    "cd['clean_ReviewContentPos'] = cd['clean_ReviewContentPos'].apply(lambda x:lemma(x))\n",
    "cd['clean_ReviewContentPos'] = cd['clean_ReviewContentPos'].apply(lambda x:convert_multiple_spaces(x))\n",
    "cd['clean_ReviewContentPos'] = cd['clean_ReviewContentPos'].apply(lambda x:remove_first_end_spaces(x))\n",
    "\n",
    "cd['clean_ReviewContentNeg'] = cd['ReviewContentNeg'].apply(lambda x:remove_punctuation_without_full(x))\n",
    "cd['clean_ReviewContentNeg'] = cd['clean_ReviewContentNeg'].apply(lambda x:remove_numbers(x))\n",
    "cd['clean_ReviewContentNeg'] = cd['clean_ReviewContentNeg'].apply(lambda x:remove_non_ascii(x))\n",
    "cd['clean_ReviewContentNeg'] = cd['clean_ReviewContentNeg'].apply(lambda x:lemma(x))\n",
    "cd['clean_ReviewContentNeg'] = cd['clean_ReviewContentNeg'].apply(lambda x:convert_multiple_spaces(x))\n",
    "cd['clean_ReviewContentNeg'] = cd['clean_ReviewContentNeg'].apply(lambda x:remove_first_end_spaces(x))\n",
    "\n",
    "cd['clean_ReviewContentNeu'] = cd['ReviewContentNeu'].apply(lambda x:remove_punctuation_without_full(x))\n",
    "cd['clean_ReviewContentNeu'] = cd['clean_ReviewContentNeu'].apply(lambda x:remove_numbers(x))\n",
    "cd['clean_ReviewContentNeu'] = cd['clean_ReviewContentNeu'].apply(lambda x:remove_non_ascii(x))\n",
    "cd['clean_ReviewContentNeu'] = cd['clean_ReviewContentNeu'].apply(lambda x:lemma(x))\n",
    "cd['clean_ReviewContentNeu'] = cd['clean_ReviewContentNeu'].apply(lambda x:convert_multiple_spaces(x)) \n",
    "cd['clean_ReviewContentNeu'] = cd['clean_ReviewContentNeu'].apply(lambda x:remove_first_end_spaces(x)) \n",
    "\n",
    "print('Preprocessing Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>Reviewcontent</th>\n",
       "      <th>ReviewContentPos</th>\n",
       "      <th>ReviewContentNeg</th>\n",
       "      <th>ReviewContentNeu</th>\n",
       "      <th>clean_Reviewcontent</th>\n",
       "      <th>clean_ReviewContentPos</th>\n",
       "      <th>clean_ReviewContentNeg</th>\n",
       "      <th>clean_ReviewContentNeu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Room, hotel, menu everything was just perf...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>The Room, hotel, menu everything was just perf...</td>\n",
       "      <td>The Room, hotel, menu everything wa just perfe...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>The Room, hotel, menu everything wa just perfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It's spacious, neat &amp; clean. Ordered misal pav...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>It's spacious, neat &amp; clean. Ordered misal pav...</td>\n",
       "      <td>It s spacious, neat clean. Ordered misal pav s...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>It s spacious, neat clean. Ordered misal pav s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent size rooms and the heating was very eff...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Decent size rooms and the heating was very eff...</td>\n",
       "      <td>Decent size room and the heating wa very effec...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Decent size room and the heating wa very effec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent resort with on the toe services by e...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Excellent resort with on the toe services by e...</td>\n",
       "      <td>Excellent resort with on the toe service by ea...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Excellent resort with on the toe service by ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[Positive]: Staff courtesy\\n[Negative]: Food w...</td>\n",
       "      <td>Staff courtesy</td>\n",
       "      <td>Food was terrible. Restaurant service pathetic</td>\n",
       "      <td>nan</td>\n",
       "      <td>Positive Staff courtesy Negative Food wa terri...</td>\n",
       "      <td>Staff courtesy</td>\n",
       "      <td>Food wa terrible. Restaurant service pathetic</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>One of the most memorable bday ever Thanku so ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>One of the most memorable bday ever Thanku so ...</td>\n",
       "      <td>One of the most memorable bday ever Thanku so ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>One of the most memorable bday ever Thanku so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Nice for parties. Food very greasy. Not recomm...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Nice for parties. Food very greasy. Not recomm...</td>\n",
       "      <td>Nice for parties. Food very greasy. Not recomm...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Nice for parties. Food very greasy. Not recomm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>The place is cozy, my reservation was upgraded...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>The place is cozy, my reservation was upgraded...</td>\n",
       "      <td>The place is cozy, my reservation wa upgraded ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>The place is cozy, my reservation wa upgraded ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row                                      Reviewcontent ReviewContentPos  \\\n",
       "0   0  The Room, hotel, menu everything was just perf...              nan   \n",
       "1   1  Excellent experience to spend time in this res...              nan   \n",
       "2   2  It's spacious, neat & clean. Ordered misal pav...              nan   \n",
       "3   3  Decent size rooms and the heating was very eff...              nan   \n",
       "4   4  If zero Rating is available, this deserves the...              nan   \n",
       "5   5  Excellent resort with on the toe services by e...              nan   \n",
       "6   6  [Positive]: Staff courtesy\\n[Negative]: Food w...   Staff courtesy   \n",
       "7   7  One of the most memorable bday ever Thanku so ...              nan   \n",
       "8   8  Nice for parties. Food very greasy. Not recomm...              nan   \n",
       "9   9  The place is cozy, my reservation was upgraded...              nan   \n",
       "\n",
       "                                 ReviewContentNeg  \\\n",
       "0                                             nan   \n",
       "1                                             nan   \n",
       "2                                             nan   \n",
       "3                                             nan   \n",
       "4                                             nan   \n",
       "5                                             nan   \n",
       "6  Food was terrible. Restaurant service pathetic   \n",
       "7                                             nan   \n",
       "8                                             nan   \n",
       "9                                             nan   \n",
       "\n",
       "                                    ReviewContentNeu  \\\n",
       "0  The Room, hotel, menu everything was just perf...   \n",
       "1  Excellent experience to spend time in this res...   \n",
       "2  It's spacious, neat & clean. Ordered misal pav...   \n",
       "3  Decent size rooms and the heating was very eff...   \n",
       "4  If zero Rating is available, this deserves the...   \n",
       "5  Excellent resort with on the toe services by e...   \n",
       "6                                                nan   \n",
       "7  One of the most memorable bday ever Thanku so ...   \n",
       "8  Nice for parties. Food very greasy. Not recomm...   \n",
       "9  The place is cozy, my reservation was upgraded...   \n",
       "\n",
       "                                 clean_Reviewcontent clean_ReviewContentPos  \\\n",
       "0  The Room, hotel, menu everything wa just perfe...                    nan   \n",
       "1  Excellent experience to spend time in this res...                    nan   \n",
       "2  It s spacious, neat clean. Ordered misal pav s...                    nan   \n",
       "3  Decent size room and the heating wa very effec...                    nan   \n",
       "4  If zero Rating is available, this deserves the...                    nan   \n",
       "5  Excellent resort with on the toe service by ea...                    nan   \n",
       "6  Positive Staff courtesy Negative Food wa terri...         Staff courtesy   \n",
       "7  One of the most memorable bday ever Thanku so ...                    nan   \n",
       "8  Nice for parties. Food very greasy. Not recomm...                    nan   \n",
       "9  The place is cozy, my reservation wa upgraded ...                    nan   \n",
       "\n",
       "                          clean_ReviewContentNeg  \\\n",
       "0                                            nan   \n",
       "1                                            nan   \n",
       "2                                            nan   \n",
       "3                                            nan   \n",
       "4                                            nan   \n",
       "5                                            nan   \n",
       "6  Food wa terrible. Restaurant service pathetic   \n",
       "7                                            nan   \n",
       "8                                            nan   \n",
       "9                                            nan   \n",
       "\n",
       "                              clean_ReviewContentNeu  \n",
       "0  The Room, hotel, menu everything wa just perfe...  \n",
       "1  Excellent experience to spend time in this res...  \n",
       "2  It s spacious, neat clean. Ordered misal pav s...  \n",
       "3  Decent size room and the heating wa very effec...  \n",
       "4  If zero Rating is available, this deserves the...  \n",
       "5  Excellent resort with on the toe service by ea...  \n",
       "6                                                nan  \n",
       "7  One of the most memorable bday ever Thanku so ...  \n",
       "8  Nice for parties. Food very greasy. Not recomm...  \n",
       "9  The place is cozy, my reservation wa upgraded ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw0 = cd.loc[:,'clean_Reviewcontent'].to_list()\n",
    "raw1 = cd.loc[:,'clean_ReviewContentPos'].to_list()\n",
    "raw2 = cd.loc[:,'clean_ReviewContentNeg'].to_list()\n",
    "raw3 = cd.loc[:,'clean_ReviewContentNeu'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_all = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "def remove_punctuation_without_gap(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in rem_all])\n",
    "    # punctuationfree = punctuationfree.replace(' ','')\n",
    "    return punctuationfree\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_lst = stopwords.words('english')\n",
    "sw = set(['dont','nothing','couldnt','wouldnt','doesnt','mustnt',\n",
    "          'couldn','wouldn','doesn','mustn','neednt','needn','wont',\n",
    "          'unfortunately','havent','arent','haven','aren','cant',\n",
    "          'didnt','didn','shouldnt','shouldn','werent','weren',\n",
    "          'shant','don','cannot','sorry','awfully','not'])\n",
    "for word in stopwords_lst:\n",
    "    sw.add(remove_punctuation_without_gap(word))\n",
    "    \n",
    "import requests\n",
    "stopwords_list = requests.get(\"https://gist.githubusercontent.com/rg089/35e00abf8941d72d419224cfd5b5925d/raw/12d899b70156fd0041fa9778d657330b024b959c/stopwords.txt\").content\n",
    "stopwords = list(set(stopwords_list.decode().splitlines()))\n",
    "for word in stopwords:\n",
    "    sw.add(remove_punctuation_without_gap(word))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    now = text\n",
    "    now = now.strip().split()\n",
    "    now = [word for word in now if word not in sw and len(word)>2]\n",
    "    text = \"\"\n",
    "    for i in range(len(now)):\n",
    "        text = text + now[i] + \" \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspect_based1(sentences):\n",
    "#     print(sentences)\n",
    "    aspects = []\n",
    "    for sentence in sentences:\n",
    "        if sentence == '':\n",
    "            continue\n",
    "        doc = nlp(sentence)\n",
    "        descriptive_term = []\n",
    "        target = []\n",
    "        adv = []\n",
    "        negation = []\n",
    "        descriptive_term_i = []\n",
    "        target_i = []\n",
    "        adv_i = []\n",
    "        negation_i = []\n",
    "        sep = []\n",
    "        sep_i = []\n",
    "        for token in doc:\n",
    "            if token.pos_ == 'PUNCT' or token.pos_ == 'CCONJ':\n",
    "                sep.append(token.text.lower())\n",
    "                sep_i.append(token.i)\n",
    "                continue\n",
    "            if (token.dep_ == 'neg' and token.pos_ =='PART') or token.text.lower()=='no':\n",
    "                negation.append(token.text.lower())\n",
    "                negation_i.append(token.i)\n",
    "                continue\n",
    "            if remove_punctuation_without_gap(token.text.lower()) in sw:\n",
    "                continue\n",
    "            if token.pos_ == 'VERB' or token.pos_ == 'ADV':\n",
    "                adv.append(token.text.lower())\n",
    "                adv_i.append(token.i)\n",
    "            if token.pos_ == 'NOUN':\n",
    "                target.append(token.text.lower())\n",
    "                target_i.append(token.i)\n",
    "            if token.pos_ == 'ADJ':\n",
    "                descriptive_term.append(token.text.lower())\n",
    "                descriptive_term_i.append(token.i)\n",
    "            if token.pos_ == 'ADJ':\n",
    "                prepend = {}\n",
    "                for child in token.children:\n",
    "                    if remove_punctuation_without_gap(child.text.lower()) in sw:\n",
    "                        continue\n",
    "                    if child.pos_ == 'ADJ' or child.pos_ == 'ADV':\n",
    "                        prepend[child.text.lower()] = child.i\n",
    "                        if child.text.lower() in descriptive_term:\n",
    "                            ind = descriptive_term.index(child.text.lower())\n",
    "                            descriptive_term.pop(ind)\n",
    "                            descriptive_term_i.pop(ind)\n",
    "                        if token.text.lower() in descriptive_term:\n",
    "                            ind = descriptive_term.index(token.text.lower())\n",
    "                            descriptive_term.pop(ind)\n",
    "                            descriptive_term_i.pop(ind)\n",
    "                if len(prepend) > 0:\n",
    "                    prepend[token.text.lower()] = token.i\n",
    "                    prepend_sorted = sorted(prepend.items(), key=lambda x: x[1]) \n",
    "                    text_to_add = ''\n",
    "                    temp = []\n",
    "                    for i in range(len(prepend_sorted)-1):\n",
    "                        text_to_add += prepend_sorted[i][0] + \" \"\n",
    "                        temp.append(prepend_sorted[i][1])\n",
    "                    text_to_add += prepend_sorted[len(prepend_sorted)-1][0]\n",
    "                    temp.append(prepend_sorted[len(prepend_sorted)-1][1])\n",
    "                    descriptive_term.append(text_to_add)\n",
    "                    descriptive_term_i.append(temp)\n",
    "        to_del = []\n",
    "        for i in range(len(adv_i)):\n",
    "            now = adv_i[i]\n",
    "            for j in range(len(descriptive_term_i)):\n",
    "                test = descriptive_term_i[j]\n",
    "                if type(test) == list:\n",
    "                    for k in range(len(test)):\n",
    "                        if now == test[k]:\n",
    "                            to_del.append(now)\n",
    "                else:\n",
    "                    if now == test:\n",
    "                        to_del.append(now)\n",
    "        for i in range(len(to_del)):\n",
    "            ind = adv_i.index(to_del[i])\n",
    "            adv.pop(ind)\n",
    "            adv_i.pop(ind)\n",
    "        \n",
    "        for i in range(len(descriptive_term_i)):\n",
    "            test = descriptive_term_i[i]\n",
    "            if type(test) == list:\n",
    "                descriptive_term_i[i] = np.mean(test)\n",
    "                \n",
    "        for i in range(len(negation_i)):\n",
    "            test = negation_i[i]\n",
    "            if type(test) == list:\n",
    "                negation_i[i] = np.mean(test)\n",
    "                \n",
    "        for i in range(len(adv_i)):\n",
    "            test = adv_i[i]\n",
    "            if type(test) == list:\n",
    "                adv_i[i] = np.mean(test)\n",
    "                \n",
    "        for i in range(len(negation_i)):\n",
    "            min_dis = 1000\n",
    "            now = -1\n",
    "            typ = -1\n",
    "            for j in range(len(descriptive_term_i)):\n",
    "                if descriptive_term_i[j] > negation_i[i] and descriptive_term_i[j] - negation_i[i] < min_dis:\n",
    "                    min_dis = descriptive_term_i[j] - negation_i[i]\n",
    "                    now = j\n",
    "                    typ = 1\n",
    "            for j in range(len(adv_i)):\n",
    "                if adv_i[j] > negation_i[i] and adv_i[j] - negation_i[i] < min_dis:\n",
    "                    min_dis = adv_i[j] - negation_i[i]\n",
    "                    now = j\n",
    "                    typ = 2\n",
    "            if now == -1:\n",
    "                for j in range(len(descriptive_term_i)):\n",
    "                    if abs(descriptive_term_i[j] - negation_i[i]) < min_dis:\n",
    "                        min_dis = descriptive_term_i[j] - negation_i[i]\n",
    "                        now = j\n",
    "                        typ = 1\n",
    "                for j in range(len(adv_i)):\n",
    "                    if abs(adv_i[j] - negation_i[i]) < min_dis:\n",
    "                        min_dis = adv_i[j] - negation_i[i]\n",
    "                        now = j\n",
    "                        typ = 2\n",
    "            if typ == 1:\n",
    "                descriptive_term[now] = negation[i] + ' ' + descriptive_term[now]\n",
    "            if typ == 2:\n",
    "                adv[now] = negation[i] + ' ' + adv[now]\n",
    "                    \n",
    "        aspects.append({'sentence':sentence,'aspect': target,\n",
    "                        'description': descriptive_term,'adv':adv,\n",
    "                        'negation':negation,'aspect_i': target_i,\n",
    "                        'description_i': descriptive_term_i,'adv_i':adv_i,\n",
    "                        'negation_i':negation_i,'sep':sep,'sep_i':sep_i})\n",
    "#     print_list(aspects)\n",
    "    return aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dictionary(a,b):\n",
    "    final = {}\n",
    "    if len(a) == 0:\n",
    "        return b\n",
    "    elif len(b) == 0:\n",
    "        return a\n",
    "    for itm in a:\n",
    "        final[itm] = [a[itm]]\n",
    "    for itm in b:\n",
    "        if itm in final:\n",
    "            now = final[itm]\n",
    "            now.append(b[itm])\n",
    "        else:\n",
    "            final[itm] = [b[itm]]\n",
    "    for itm in final:\n",
    "        now = final[itm]\n",
    "        score = np.mean(now)\n",
    "        final[itm] = score\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspect_relation1(dict_now):\n",
    "    ans = {}\n",
    "    return ans\n",
    "\n",
    "def aspect_relation2(dict_now,column):\n",
    "    ans = {}\n",
    "    target = dict_now['aspect']\n",
    "    sen = dict_now['sentence']\n",
    "    if column == 'POSITIVE':\n",
    "        for i in range(len(target)):\n",
    "            ans[target[i]] = 1\n",
    "    elif column == 'NEGATIVE':\n",
    "        for i in range(len(target)):\n",
    "            ans[target[i]] = -1\n",
    "    else:\n",
    "        s1 = bert_distilbert(sen)[0]\n",
    "        r1 = 1000\n",
    "        if s1['label'] == 'POSITIVE':\n",
    "            r1 = s1['score']\n",
    "        elif s1['label'] == 'NEGATIVE':\n",
    "            r1 = -s1['score']\n",
    "            \n",
    "        s2 = roberta_english(sen)[0]\n",
    "        r2 = 1000\n",
    "        if s2['label'] == 'POSITIVE':\n",
    "            r2 = s2['score']\n",
    "        elif s2['label'] == 'NEGATIVE':\n",
    "            r2 = -s2['score']\n",
    "            \n",
    "        score = round((r1+r2)/2,5)\n",
    "        for i in range(len(target)):\n",
    "            ans[target[i]] = score\n",
    "    return ans\n",
    "\n",
    "def aspect_relation3(dict_now):\n",
    "    ans = {}\n",
    "    target = dict_now['aspect']\n",
    "    sen = dict_now['sentence']\n",
    "\n",
    "    s1 = bert_distilbert(sen)[0]\n",
    "    r1 = 1000\n",
    "    if s1['label'] == 'POSITIVE':\n",
    "        r1 = s1['score']\n",
    "    elif s1['label'] == 'NEGATIVE':\n",
    "        r1 = -s1['score']\n",
    "\n",
    "    s2 = roberta_english(sen)[0]\n",
    "    r2 = 1000\n",
    "    if s2['label'] == 'POSITIVE':\n",
    "        r2 = s2['score']\n",
    "    elif s2['label'] == 'NEGATIVE':\n",
    "        r2 = -s2['score']\n",
    "\n",
    "    score = round((r1+r2)/2,5)\n",
    "    ans[target[0]] = score\n",
    "    return ans\n",
    "\n",
    "def aspect_relation4(dict_now):\n",
    "    ans = {}\n",
    "    target = dict_now['aspect']\n",
    "    sen = dict_now['sentence']\n",
    "\n",
    "    s1 = bert_distilbert(sen)[0]\n",
    "    r1 = 1000\n",
    "    if s1['label'] == 'POSITIVE':\n",
    "        r1 = s1['score']\n",
    "    elif s1['label'] == 'NEGATIVE':\n",
    "        r1 = -s1['score']\n",
    "\n",
    "    s2 = roberta_english(sen)[0]\n",
    "    r2 = 1000\n",
    "    if s2['label'] == 'POSITIVE':\n",
    "        r2 = s2['score']\n",
    "    elif s2['label'] == 'NEGATIVE':\n",
    "        r2 = -s2['score']\n",
    "\n",
    "    score = round((r1+r2)/2,5)\n",
    "    for i in range(len(target)):\n",
    "        ans[target[i]] = score\n",
    "    return ans\n",
    "\n",
    "def aspect_relation5(dict_now):\n",
    "    ans = {}\n",
    "    target = dict_now['aspect']\n",
    "    sen = dict_now['sentence']\n",
    "\n",
    "    s1 = bert_distilbert(sen)[0]\n",
    "    r1 = 1000\n",
    "    if s1['label'] == 'POSITIVE':\n",
    "        r1 = s1['score']\n",
    "    elif s1['label'] == 'NEGATIVE':\n",
    "        r1 = -s1['score']\n",
    "\n",
    "    s2 = roberta_english(sen)[0]\n",
    "    r2 = 1000\n",
    "    if s2['label'] == 'POSITIVE':\n",
    "        r2 = s2['score']\n",
    "    elif s2['label'] == 'NEGATIVE':\n",
    "        r2 = -s2['score']\n",
    "\n",
    "    score = round((r1+r2)/2,5)\n",
    "    ans[target[0]] = score\n",
    "    return ans\n",
    "\n",
    "def aspect_relation6(dict_now):\n",
    "    ans = {}\n",
    "    target = dict_now['aspect']\n",
    "    target_i = dict_now['aspect_i']\n",
    "    words1 = dict_now['description']\n",
    "    words2 = dict_now['adv']\n",
    "    wordsi_1 = dict_now['description_i']\n",
    "    wordsi_2 = dict_now['adv_i']\n",
    "    wordsf_1 = []\n",
    "    wordsf_2 = []\n",
    "    for i in range(len(wordsi_1)):\n",
    "        now = wordsi_1[i]\n",
    "        if type(now) == list:\n",
    "            wordsf_1.append(np.mean(now))\n",
    "        else:\n",
    "            wordsf_1.append(now)\n",
    "            \n",
    "    for i in range(len(wordsi_2)):\n",
    "        now = wordsi_2[i]\n",
    "        if type(now) == list:\n",
    "            wordsf_2.append(np.mean(now))\n",
    "        else:\n",
    "            wordsf_2.append(now)\n",
    "    X = target\n",
    "    XX = target_i\n",
    "    Y = words1 + words2\n",
    "    YY = wordsf_1 + wordsf_2\n",
    "    \n",
    "    y = copy.deepcopy(Y)\n",
    "    yy = copy.deepcopy(YY)\n",
    "    ans_list = []\n",
    "    ind_list = []\n",
    "    for i in range(len(XX)):\n",
    "        min_dis = 1000\n",
    "        now = 0\n",
    "        for j in range(len(YY)):\n",
    "            if abs(YY[j]-XX[i]) < min_dis:\n",
    "                min_dis = abs(YY[j]-XX[i])\n",
    "                now = j\n",
    "        ans_list.append(Y[now])\n",
    "        ind_list.append(now)\n",
    "    ind_list = np.sort(list(set(ind_list)))[::-1].tolist()\n",
    "    \n",
    "    for i in range(len(ind_list)):\n",
    "        index = ind_list[i]\n",
    "        y.pop(index)\n",
    "        yy.pop(index)\n",
    "    \n",
    "    relation = []\n",
    "    for i in range(len(ans_list)):\n",
    "        relation.append([target[i],ans_list[i]])\n",
    "    \n",
    "    for i in range(len(yy)):\n",
    "        min_dis = 1000\n",
    "        now = 0\n",
    "        for j in range(len(XX)):\n",
    "            if abs(yy[i]-XX[j]) < min_dis:\n",
    "                min_dis = abs(yy[i]-XX[j])\n",
    "                now = j\n",
    "        relation.append([X[now],y[i]])\n",
    "        \n",
    "    \n",
    "    for i in range(len(target)):\n",
    "        ans[target[i]] = []\n",
    "    for i in range(len(relation)):\n",
    "        word = relation[i][0]\n",
    "        sen = relation[i][1]\n",
    "        \n",
    "        s1 = bert_distilbert(sen)[0]\n",
    "        r1 = 1000\n",
    "        if s1['label'] == 'POSITIVE':\n",
    "            r1 = s1['score']\n",
    "        elif s1['label'] == 'NEGATIVE':\n",
    "            r1 = -s1['score']\n",
    "\n",
    "        s2 = roberta_english(sen)[0]\n",
    "        r2 = 1000\n",
    "        if s2['label'] == 'POSITIVE':\n",
    "            r2 = s2['score']\n",
    "        elif s2['label'] == 'NEGATIVE':\n",
    "            r2 = -s2['score']\n",
    "\n",
    "        score = round((r1+r2)/2,5)\n",
    "        \n",
    "        list_now = ans[word]\n",
    "        list_now.append(score)\n",
    "        ans[word] = list_now\n",
    "    \n",
    "    for itm in ans:\n",
    "        value = ans[itm]\n",
    "        value_mean = np.mean(value)\n",
    "        ans[itm] = value_mean\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_detection(ab,column):\n",
    "    rows = len(ab)\n",
    "    final = {}\n",
    "    for i in range(rows):\n",
    "        dict_now = ab[i]\n",
    "        NC = len(dict_now['aspect'])\n",
    "        DC = len(dict_now['description']) + len(dict_now['adv'])\n",
    "        if NC == 0:\n",
    "#             print('Type 1')\n",
    "            ans = aspect_relation1(dict_now)\n",
    "            final = combine_dictionary(ans,final)\n",
    "        elif DC == 0:\n",
    "#             print('Type 2')\n",
    "            ans = aspect_relation2(dict_now,column)\n",
    "            final = combine_dictionary(ans,final)\n",
    "        elif NC == 1 and DC == 1:\n",
    "#             print('Type 3')\n",
    "            ans = aspect_relation3(dict_now)\n",
    "            final = combine_dictionary(ans,final)\n",
    "        elif NC > 1 and DC == 1:\n",
    "#             print('Type 4')\n",
    "            ans = aspect_relation4(dict_now)\n",
    "            final = combine_dictionary(ans,final)\n",
    "        elif NC == 1 and DC > 1:\n",
    "#             print('Type 5')\n",
    "            ans = aspect_relation5(dict_now)\n",
    "            final = combine_dictionary(ans,final)\n",
    "        elif NC > 1 and DC > 1:\n",
    "#             print('Type 6')\n",
    "            ans = aspect_relation6(dict_now)\n",
    "            final = combine_dictionary(ans,final)\n",
    "        else:\n",
    "            print('Type X')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1345, 2)\n"
     ]
    }
   ],
   "source": [
    "helper = pd.read_csv('aspect_dictionary.csv')\n",
    "print(helper.shape)\n",
    "helper['Phrase'] = helper['Phrase'].astype(str)\n",
    "helper['Class'] = helper['Class'].astype(str)\n",
    "keywords = list(set(helper.loc[:,'Class'].to_list()))\n",
    "classes_dict = {}\n",
    "for i in range(len(helper)):\n",
    "    add = lemma(remove_first_end_spaces(helper.loc[i,'Phrase']))\n",
    "    add = remove_punctuation_without_full(add)\n",
    "    add = remove_first_end_spaces(add)\n",
    "    classes_dict[add] = helper.loc[i,'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from scipy import spatial\n",
    "glove_model = api.load('glove-twitter-25')\n",
    "\n",
    "def find_aspect(aspect,keywords):\n",
    "    sim = []\n",
    "    sample_glove_embedding1=glove_model[aspect.lower()]\n",
    "    for i in range(len(keywords)):\n",
    "        sample_glove_embedding2=glove_model[keywords[i].lower()]\n",
    "        res = 1 - spatial.distance.cosine(sample_glove_embedding1, sample_glove_embedding2)\n",
    "        sim.append(res)\n",
    "    x = np.argmax(sim)\n",
    "    return keywords[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_class(aspect, keywords, classes_dict):\n",
    "    aspect = lemma(remove_first_end_spaces(aspect))\n",
    "    aspect = remove_punctuation_without_full(aspect)\n",
    "    aspect = remove_first_end_spaces(aspect)\n",
    "    if aspect in classes_dict:\n",
    "        if classes_dict[aspect] == 'dump':\n",
    "            ret = -1\n",
    "            return ret\n",
    "        return classes_dict[aspect]\n",
    "    try:\n",
    "        ret = find_aspect(aspect, keywords)\n",
    "    except:\n",
    "        ret = -1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_classes(dict_now,keywords,classes_dict):\n",
    "    ans = {}\n",
    "    for itm in dict_now:\n",
    "        class_add = find_class(itm,keywords,classes_dict)\n",
    "        if class_add == -1:\n",
    "            continue\n",
    "        if class_add in ans:\n",
    "            now = ans[class_add]\n",
    "            now.append(dict_now[itm])\n",
    "            ans[class_add] = now\n",
    "        else:\n",
    "            ans[class_add] = [dict_now[itm]]\n",
    "    for itm in ans:\n",
    "        now = ans[itm]\n",
    "        score = np.mean(now)\n",
    "        ans[itm] = round(score,5)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_sentiment(text):\n",
    "    snip = text\n",
    "    now = bert_distilbert(snip)[0]\n",
    "    x = 0\n",
    "    y = 0\n",
    "    if now['label'] == 'POSITIVE':\n",
    "        x += now['score']\n",
    "    else:\n",
    "        x -= now['score']\n",
    "    temp = roberta_english(snip)[0]\n",
    "    if now['label'] == 'POSITIVE':\n",
    "        y += now['score']\n",
    "    else:\n",
    "        y -= now['score']\n",
    "#     print(\"Overall Sentiment Score:\",round((x+y)/2,5))\n",
    "    return round((x+y)/2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_aspect_class_relation(relation, td, keywords, classes_dict):\n",
    "    for itm in td:\n",
    "        relation[itm] = find_class(itm, keywords, classes_dict)\n",
    "    return relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1079, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# for i in range(cd.shape[0]):\n",
    "for i in range(cd.shape[0]):\n",
    "#     print('Run:',i)\n",
    "    try:\n",
    "        text = cd.loc[i,'clean_Reviewcontent']\n",
    "        cd.loc[i,'Sentiment Score'] = ensemble_sentiment(text)\n",
    "\n",
    "        pol_prop = {}\n",
    "        index = i\n",
    "        snip = raw1[index]\n",
    "        text = snip\n",
    "        text = snip.split('.')\n",
    "        ab = aspect_based1(text)\n",
    "        # pos_display(snip)\n",
    "        # dataframe_display(snip)\n",
    "        # ensemble_sentiment(snip)\n",
    "        # polarity_ab(ab)\n",
    "        \n",
    "        relation = {}\n",
    "\n",
    "        td = type_detection(ab,'POSITIVE')\n",
    "        relation = find_aspect_class_relation(relation, td, keywords, classes_dict)\n",
    "        c1 = collate_classes(td,keywords,classes_dict)\n",
    "\n",
    "        index = i\n",
    "        snip = raw2[index]\n",
    "        text = snip\n",
    "        text = snip.split('.')\n",
    "        ab = aspect_based1(text)\n",
    "        # pos_display(snip)\n",
    "        # dataframe_display(snip)\n",
    "        # ensemble_sentiment(snip)\n",
    "        # polarity_ab(ab)\n",
    "\n",
    "        td = type_detection(ab,'NEGATIVE')\n",
    "        relation = find_aspect_class_relation(relation, td, keywords, classes_dict)\n",
    "        c2 = collate_classes(td,keywords,classes_dict)\n",
    "\n",
    "        index = i\n",
    "        snip = raw3[index]\n",
    "        text = snip\n",
    "        text = snip.split('.')\n",
    "        ab = aspect_based1(text)\n",
    "        # pos_display(snip)\n",
    "        # dataframe_display(snip)\n",
    "        # ensemble_sentiment(snip)\n",
    "        # polarity_ab(ab)\n",
    "\n",
    "        td = type_detection(ab,'NEUTRAL')\n",
    "        relation = find_aspect_class_relation(relation, td, keywords, classes_dict)\n",
    "        c3 = collate_classes(td,keywords,classes_dict)\n",
    "\n",
    "        pol_prop = combine_dictionary(pol_prop,c1)\n",
    "        pol_prop = combine_dictionary(pol_prop,c2)\n",
    "        pol_prop = combine_dictionary(pol_prop,c3)\n",
    "\n",
    "#         for itm in relation:\n",
    "#             if itm in classes_dict:\n",
    "#                 continue\n",
    "#             print(itm,'--->',relation[itm])\n",
    "        cd.loc[i,'Relation'] = str(relation)\n",
    "        cd.loc[i,'Properties'] = str(pol_prop)\n",
    "#         print('---------------------------------')\n",
    "    except Exception as e:\n",
    "        continue\n",
    "        print(i,e)\n",
    "        exc_type, exc_obj, exc_tb = sys.exc_info()\n",
    "        fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]\n",
    "        print(exc_type, fname, exc_tb.tb_lineno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.to_csv('results_sample_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>Reviewcontent</th>\n",
       "      <th>ReviewContentPos</th>\n",
       "      <th>ReviewContentNeg</th>\n",
       "      <th>ReviewContentNeu</th>\n",
       "      <th>clean_Reviewcontent</th>\n",
       "      <th>clean_ReviewContentPos</th>\n",
       "      <th>clean_ReviewContentNeg</th>\n",
       "      <th>clean_ReviewContentNeu</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Properties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Room, hotel, menu everything was just perf...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>The Room, hotel, menu everything was just perf...</td>\n",
       "      <td>The Room, hotel, menu everything wa just perfe...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>The Room, hotel, menu everything wa just perfe...</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>{'room': 'room', 'view': 'location', 'stay': '...</td>\n",
       "      <td>{'room': 0.99924, 'location': 0.99929, 'food':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Excellent experience to spend time in this res...</td>\n",
       "      <td>0.99968</td>\n",
       "      <td>{'food': 'food', 'atmosphere': 'facilities', '...</td>\n",
       "      <td>{'food': 0.9993, 'facilities': 0.99877, 'time'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It's spacious, neat &amp; clean. Ordered misal pav...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>It's spacious, neat &amp; clean. Ordered misal pav...</td>\n",
       "      <td>It s spacious, neat clean. Ordered misal pav s...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>It s spacious, neat clean. Ordered misal pav s...</td>\n",
       "      <td>0.99814</td>\n",
       "      <td>{'snack': 'food', 'misal': -1, 'snacks': 'food'}</td>\n",
       "      <td>{'food': 0.4686}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent size rooms and the heating was very eff...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Decent size rooms and the heating was very eff...</td>\n",
       "      <td>Decent size room and the heating wa very effec...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Decent size room and the heating wa very effec...</td>\n",
       "      <td>0.99920</td>\n",
       "      <td>{'location': 'location', 'market': 'location',...</td>\n",
       "      <td>{'location': 0.97639, 'time': 0.49284, 'facili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>If zero Rating is available, this deserves the...</td>\n",
       "      <td>-0.99741</td>\n",
       "      <td>{'behaviour': 'service', 'staff': 'staff', 'ho...</td>\n",
       "      <td>{'service': -0.33469, 'staff': 0.49978, 'hotel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row                                      Reviewcontent ReviewContentPos  \\\n",
       "0   0  The Room, hotel, menu everything was just perf...              nan   \n",
       "1   1  Excellent experience to spend time in this res...              nan   \n",
       "2   2  It's spacious, neat & clean. Ordered misal pav...              nan   \n",
       "3   3  Decent size rooms and the heating was very eff...              nan   \n",
       "4   4  If zero Rating is available, this deserves the...              nan   \n",
       "\n",
       "  ReviewContentNeg                                   ReviewContentNeu  \\\n",
       "0              nan  The Room, hotel, menu everything was just perf...   \n",
       "1              nan  Excellent experience to spend time in this res...   \n",
       "2              nan  It's spacious, neat & clean. Ordered misal pav...   \n",
       "3              nan  Decent size rooms and the heating was very eff...   \n",
       "4              nan  If zero Rating is available, this deserves the...   \n",
       "\n",
       "                                 clean_Reviewcontent clean_ReviewContentPos  \\\n",
       "0  The Room, hotel, menu everything wa just perfe...                    nan   \n",
       "1  Excellent experience to spend time in this res...                    nan   \n",
       "2  It s spacious, neat clean. Ordered misal pav s...                    nan   \n",
       "3  Decent size room and the heating wa very effec...                    nan   \n",
       "4  If zero Rating is available, this deserves the...                    nan   \n",
       "\n",
       "  clean_ReviewContentNeg                             clean_ReviewContentNeu  \\\n",
       "0                    nan  The Room, hotel, menu everything wa just perfe...   \n",
       "1                    nan  Excellent experience to spend time in this res...   \n",
       "2                    nan  It s spacious, neat clean. Ordered misal pav s...   \n",
       "3                    nan  Decent size room and the heating wa very effec...   \n",
       "4                    nan  If zero Rating is available, this deserves the...   \n",
       "\n",
       "   Sentiment Score                                           Relation  \\\n",
       "0          0.99988  {'room': 'room', 'view': 'location', 'stay': '...   \n",
       "1          0.99968  {'food': 'food', 'atmosphere': 'facilities', '...   \n",
       "2          0.99814   {'snack': 'food', 'misal': -1, 'snacks': 'food'}   \n",
       "3          0.99920  {'location': 'location', 'market': 'location',...   \n",
       "4         -0.99741  {'behaviour': 'service', 'staff': 'staff', 'ho...   \n",
       "\n",
       "                                          Properties  \n",
       "0  {'room': 0.99924, 'location': 0.99929, 'food':...  \n",
       "1  {'food': 0.9993, 'facilities': 0.99877, 'time'...  \n",
       "2                                   {'food': 0.4686}  \n",
       "3  {'location': 0.97639, 'time': 0.49284, 'facili...  \n",
       "4  {'service': -0.33469, 'staff': 0.49978, 'hotel...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
